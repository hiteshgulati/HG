{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta, date\n",
    "import time\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_download(file_path, file_url):\n",
    "    r = requests.get(file_url, stream=True)\n",
    "    with open(file_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=256):\n",
    "            fd.write(chunk)\n",
    "\n",
    "def daterange(start_date, end_date, inclusive=True):\n",
    "    if inclusive:\n",
    "        included_dates = 1\n",
    "    else:\n",
    "        included_dates = 0\n",
    "    for n in range(int((end_date-start_date).days+included_dates)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hitesh.gulati\\\\Space\\\\ALM\\\\Data\\\\BhavCopy'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_file_directory = os.path.join(os.getcwd(), \"Data\", \"BhavCopy\",\"tempfolder\",\"sample.zip\")\n",
    "file_directory = os.path.join(os.getcwd(), \"Data\", \"BhavCopy\")\n",
    "\n",
    "file_directory\n",
    "# missed_dates_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Dec 31\r"
     ]
    }
   ],
   "source": [
    "missed_dates = {}\n",
    "for d in daterange(dt(1995,1,1),dt(1997,12,31)):\n",
    "    print(d.strftime(\"%d %b %y\"),end='\\r')\n",
    "    url_pre = \"https://www1.nseindia.com/content/historical/EQUITIES/\"\n",
    "    url_post = \"bhav.csv.zip\"\n",
    "\n",
    "    url = url_pre + d.strftime(\"%Y/%b/\").upper() + \"cm\" + d.strftime(\"%d%b%Y\").upper() + url_post\n",
    "\n",
    "    file_download(temp_file_directory,url)\n",
    "    try:\n",
    "        with zipfile.ZipFile(temp_file_directory,\"r\") as zip_ref:\n",
    "            zip_ref.extractall(path=file_directory)\n",
    "    except Exception as e:\n",
    "        missed_dates[d] = e\n",
    "\n",
    "missed_dates_all.update(missed_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200 31 Dec 9701 May 1420 Mar 1517 May 1510 Oct 1510 Nov 15 16 Oct 0803 Jun 0909 Nov 1030 Apr 1127 Jun 1121 Jul 1129 Jul 1120 Jul 0512 Oct 0502 Feb 0617 Oct 0607 Mar 0705 Apr 0725 Jul 0714 Aug 0726 Nov 0711 Dec 0727 Jan 0101 May 01 17 Nov 0102 Dec 01 02 Feb 0203 Oct 02 03 Mar 9610 Aug 9609 Sep 96\r"
     ]
    }
   ],
   "source": [
    "missed_dates = {}\n",
    "for idx,d in enumerate(missed_dates_df['date']):\n",
    "    \n",
    "    url_pre = \"https://www1.nseindia.com/content/historical/EQUITIES/\"\n",
    "    url_post = \"bhav.csv.zip\"\n",
    "\n",
    "    url = url_pre + d.strftime(\"%Y/%b/\").upper() + \"cm\" + d.strftime(\"%d%b%Y\").upper() + url_post\n",
    "\n",
    "    # file_download(temp_file_directory,url)\n",
    "    try:\n",
    "        file_download(temp_file_directory,url)\n",
    "        with zipfile.ZipFile(temp_file_directory,\"r\") as zip_ref:\n",
    "            zip_ref.extractall(path=file_directory)\n",
    "    except Exception as e:\n",
    "        missed_dates[d] = e\n",
    "        print(idx, d.strftime(\"%d %b %y\"),end='\\r')\n",
    "\n",
    "missed_dates_all.update(missed_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6201, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_dates_df = pd.DataFrame.from_dict(missed_dates_all,orient='index')\n",
    "missed_dates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_dates_df.to_csv(os.path.join(file_directory,\"missed_dates.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_dates_df = pd.read_csv(os.path.join(file_directory,\"missed_dates.csv\"))\n",
    "missed_dates_df['date'] = pd.to_datetime(missed_dates_df['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6201, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_dates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-01-25 00:00:00')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(missed_dates_all)[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pre = \"https://www1.nseindia.com/content/historical/EQUITIES/\"\n",
    "url_post = \"bhav.csv.zip\"\n",
    "\n",
    "url = url_pre + d.strftime(\"%Y/%b/\").upper() + \"cm\" + d.strftime(\"%d%b%Y\").upper() + url_post\n",
    "\n",
    "# file_download(temp_file_directory,url)\n",
    "try:\n",
    "    file_download(temp_file_directory,url)\n",
    "    with zipfile.ZipFile(temp_file_directory,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(path=file_directory)\n",
    "except Exception as e:\n",
    "    missed_dates[d] = e\n",
    "    print(idx, d.strftime(\"%d %b %y\"),end='\\r')\n",
    "\n",
    "missed_dates_all.update(missed_dates)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73601e6817793ffeb38c6f308fcb2845e43bc38d38ec318ab5bd060d656de52c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
